Wed Dec 18 13:32:15 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:3A:00.0 Off |                    0 |
| N/A   30C    P0             41W /  300W |       1MiB /  32768MiB |      0%   E. Process |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Warning: ['training_args', 'lr'] is not a list; must be for hparam search
Warning: ['model_args', 'hidden_size'] is not a list; must be for hparam search
Warning: ['model_args', 'num_heads'] is not a list; must be for hparam search
Warning: ['model_args', 'num_layers'] is not a list; must be for hparam search

##################################################
EXPERIMENT 1/1
Save folder: /work3/s194262/GitHub/fault_management_uds/models/transformer/lr=0.0005_hidden_size=32_num_heads=1_num_layers=2_241218_1332

Hyperparameters: {'training_args/lr': 0.0005, 'model_args/hidden_size': 32, 'model_args/num_heads': 1, 'model_args/num_layers': 2}
##################################################

Validity: 94418 minutes are invalid.
Data validation passed.
Model does not have additional configurations.
Using CUDA
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.17it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/62089 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s] Epoch 0:   8%|â–Š         | 5000/62089 [01:27<16:34, 57.43it/s]Epoch 0:   8%|â–Š         | 5000/62089 [01:27<16:34, 57.43it/s, v_num=0, train_loss_step=1.24e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [02:53<15:02, 57.70it/s, v_num=0, train_loss_step=1.24e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [02:53<15:02, 57.70it/s, v_num=0, train_loss_step=3.28e-5]Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:19<13:34, 57.83it/s, v_num=0, train_loss_step=3.28e-5]Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:19<13:34, 57.83it/s, v_num=0, train_loss_step=2.67e-6]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:45<12:08, 57.81it/s, v_num=0, train_loss_step=2.67e-6]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:45<12:08, 57.81it/s, v_num=0, train_loss_step=2.65e-6]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:12<10:41, 57.82it/s, v_num=0, train_loss_step=2.65e-6]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:12<10:41, 57.82it/s, v_num=0, train_loss_step=3.92e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:39<09:15, 57.79it/s, v_num=0, train_loss_step=3.92e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:39<09:15, 57.78it/s, v_num=0, train_loss_step=4.41e-6]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:05<07:48, 57.78it/s, v_num=0, train_loss_step=4.41e-6]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:05<07:48, 57.78it/s, v_num=0, train_loss_step=2.4e-6] Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:32<06:22, 57.77it/s, v_num=0, train_loss_step=2.4e-6]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:32<06:22, 57.77it/s, v_num=0, train_loss_step=0.000173]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:59<04:55, 57.76it/s, v_num=0, train_loss_step=0.000173]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:59<04:55, 57.76it/s, v_num=0, train_loss_step=1.43e-5] Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:25<03:29, 57.74it/s, v_num=0, train_loss_step=1.43e-5]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:25<03:29, 57.74it/s, v_num=0, train_loss_step=2.15e-6]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:52<02:02, 57.72it/s, v_num=0, train_loss_step=2.15e-6]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:52<02:02, 57.72it/s, v_num=0, train_loss_step=2.02e-6]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:19<00:36, 57.72it/s, v_num=0, train_loss_step=2.02e-6]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:19<00:36, 57.72it/s, v_num=0, train_loss_step=1.16e-5]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:55<00:00, 57.74it/s, v_num=0, train_loss_step=1.16e-5]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:55<00:00, 57.74it/s, v_num=0, train_loss_step=1.62e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:00<01:39, 82.11it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:01<00:38, 82.17it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:40<00:00, 82.14it/s][A
                                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:36<00:00, 50.23it/s, v_num=0, train_loss_step=1.62e-6, val_loss=7.22e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:36<00:00, 50.23it/s, v_num=0, train_loss_step=1.62e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]            Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:27<16:33, 57.47it/s, v_num=0, train_loss_step=1.62e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:27<16:33, 57.47it/s, v_num=0, train_loss_step=8.7e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5] Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [02:52<14:58, 57.96it/s, v_num=0, train_loss_step=8.7e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [02:52<14:58, 57.96it/s, v_num=0, train_loss_step=7.36e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:17<13:28, 58.21it/s, v_num=0, train_loss_step=7.36e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:17<13:28, 58.21it/s, v_num=0, train_loss_step=2.81e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:43<12:02, 58.27it/s, v_num=0, train_loss_step=2.81e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:43<12:02, 58.27it/s, v_num=0, train_loss_step=3.28e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:08<10:36, 58.31it/s, v_num=0, train_loss_step=3.28e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:08<10:36, 58.31it/s, v_num=0, train_loss_step=2.42e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:34<09:10, 58.31it/s, v_num=0, train_loss_step=2.42e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:34<09:10, 58.31it/s, v_num=0, train_loss_step=3.89e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:59<07:44, 58.34it/s, v_num=0, train_loss_step=3.89e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:59<07:44, 58.34it/s, v_num=0, train_loss_step=2.07e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:25<06:18, 58.39it/s, v_num=0, train_loss_step=2.07e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:25<06:18, 58.39it/s, v_num=0, train_loss_step=0.000187, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:50<04:52, 58.41it/s, v_num=0, train_loss_step=0.000187, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:50<04:52, 58.41it/s, v_num=0, train_loss_step=2.76e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5] Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:15<03:26, 58.45it/s, v_num=0, train_loss_step=2.76e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:15<03:26, 58.45it/s, v_num=0, train_loss_step=1.31e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:40<02:01, 58.49it/s, v_num=0, train_loss_step=1.31e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:40<02:01, 58.49it/s, v_num=0, train_loss_step=1.31e-5, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:05<00:35, 58.52it/s, v_num=0, train_loss_step=1.31e-5, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:05<00:35, 58.52it/s, v_num=0, train_loss_step=5.64e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:41<00:00, 58.50it/s, v_num=0, train_loss_step=5.64e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:41<00:00, 58.50it/s, v_num=0, train_loss_step=5.65e-6, val_loss=7.22e-6, train_loss_epoch=7.61e-5]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:00<01:39, 82.62it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:01<00:38, 82.64it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:39<00:00, 82.65it/s][A
                                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:21<00:00, 50.85it/s, v_num=0, train_loss_step=5.65e-6, val_loss=6.11e-6, train_loss_epoch=7.61e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:21<00:00, 50.85it/s, v_num=0, train_loss_step=5.65e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=5.65e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]            Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=5.65e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:27<16:41, 57.02it/s, v_num=0, train_loss_step=5.65e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:27<16:41, 57.02it/s, v_num=0, train_loss_step=3.12e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [02:53<15:02, 57.73it/s, v_num=0, train_loss_step=3.12e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [02:53<15:02, 57.73it/s, v_num=0, train_loss_step=6.9e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6] Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:18<13:32, 57.99it/s, v_num=0, train_loss_step=6.9e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:18<13:32, 57.99it/s, v_num=0, train_loss_step=6.63e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:43<12:02, 58.28it/s, v_num=0, train_loss_step=6.63e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:43<12:02, 58.28it/s, v_num=0, train_loss_step=3.9e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6] Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:07<10:33, 58.53it/s, v_num=0, train_loss_step=3.9e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:07<10:33, 58.53it/s, v_num=0, train_loss_step=6.03e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:30<09:06, 58.74it/s, v_num=0, train_loss_step=6.03e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:30<09:06, 58.74it/s, v_num=0, train_loss_step=3.11e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:54<07:40, 58.86it/s, v_num=0, train_loss_step=3.11e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:54<07:40, 58.86it/s, v_num=0, train_loss_step=2.15e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:18<06:14, 58.96it/s, v_num=0, train_loss_step=2.15e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:18<06:14, 58.96it/s, v_num=0, train_loss_step=2.2e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6] Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:42<04:49, 59.00it/s, v_num=0, train_loss_step=2.2e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:42<04:49, 59.00it/s, v_num=0, train_loss_step=4.42e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:06<03:24, 59.10it/s, v_num=0, train_loss_step=4.42e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:06<03:24, 59.10it/s, v_num=0, train_loss_step=4.54e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:29<01:59, 59.14it/s, v_num=0, train_loss_step=4.54e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:29<01:59, 59.14it/s, v_num=0, train_loss_step=4.09e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:53<00:35, 59.19it/s, v_num=0, train_loss_step=4.09e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:53<00:35, 59.19it/s, v_num=0, train_loss_step=2.88e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:28<00:00, 59.20it/s, v_num=0, train_loss_step=2.88e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:28<00:00, 59.20it/s, v_num=0, train_loss_step=1.82e-6, val_loss=6.11e-6, train_loss_epoch=6.79e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:59<01:36, 84.72it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:58<00:37, 84.72it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:35<00:00, 84.71it/s][A
                                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:04<00:00, 51.54it/s, v_num=0, train_loss_step=1.82e-6, val_loss=4.78e-6, train_loss_epoch=6.79e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:04<00:00, 51.54it/s, v_num=0, train_loss_step=1.82e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.82e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]            Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.82e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:24<16:03, 59.24it/s, v_num=0, train_loss_step=1.82e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:24<16:03, 59.24it/s, v_num=0, train_loss_step=1.92e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:35, 59.48it/s, v_num=0, train_loss_step=1.92e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:35, 59.48it/s, v_num=0, train_loss_step=2.45e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:12<13:12, 59.46it/s, v_num=0, train_loss_step=2.45e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:12<13:12, 59.46it/s, v_num=0, train_loss_step=2.48e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:36<11:47, 59.47it/s, v_num=0, train_loss_step=2.48e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:36<11:47, 59.47it/s, v_num=0, train_loss_step=3.77e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:00<10:23, 59.50it/s, v_num=0, train_loss_step=3.77e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:00<10:23, 59.50it/s, v_num=0, train_loss_step=1.99e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:23<08:59, 59.53it/s, v_num=0, train_loss_step=1.99e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:23<08:59, 59.53it/s, v_num=0, train_loss_step=4.4e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6] Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:48<07:35, 59.49it/s, v_num=0, train_loss_step=4.4e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:48<07:35, 59.49it/s, v_num=0, train_loss_step=4.28e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:12<06:11, 59.50it/s, v_num=0, train_loss_step=4.28e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:12<06:11, 59.50it/s, v_num=0, train_loss_step=3.26e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:35<04:47, 59.53it/s, v_num=0, train_loss_step=3.26e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:35<04:47, 59.53it/s, v_num=0, train_loss_step=6.75e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:00<03:23, 59.48it/s, v_num=0, train_loss_step=6.75e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:00<03:23, 59.48it/s, v_num=0, train_loss_step=3.45e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:24<01:59, 59.48it/s, v_num=0, train_loss_step=3.45e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:24<01:59, 59.48it/s, v_num=0, train_loss_step=3.17e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:48<00:35, 59.47it/s, v_num=0, train_loss_step=3.17e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:48<00:35, 59.47it/s, v_num=0, train_loss_step=4.9e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6] Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:24<00:00, 59.44it/s, v_num=0, train_loss_step=4.9e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:24<00:00, 59.44it/s, v_num=0, train_loss_step=4.75e-6, val_loss=4.78e-6, train_loss_epoch=6.07e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:59<01:37, 84.01it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:58<00:38, 84.13it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:36<00:00, 84.17it/s][A
                                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:01<00:00, 51.68it/s, v_num=0, train_loss_step=4.75e-6, val_loss=5.74e-6, train_loss_epoch=6.07e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:01<00:00, 51.68it/s, v_num=0, train_loss_step=4.75e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]            Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:25<16:15, 58.52it/s, v_num=0, train_loss_step=4.75e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:25<16:15, 58.52it/s, v_num=0, train_loss_step=6.37e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [02:49<14:41, 59.10it/s, v_num=0, train_loss_step=6.37e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [02:49<14:41, 59.10it/s, v_num=0, train_loss_step=8.52e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:13<13:14, 59.28it/s, v_num=0, train_loss_step=8.52e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:13<13:14, 59.28it/s, v_num=0, train_loss_step=0.000131, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:36<11:48, 59.40it/s, v_num=0, train_loss_step=0.000131, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:36<11:48, 59.40it/s, v_num=0, train_loss_step=2.91e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6] Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:01<10:24, 59.38it/s, v_num=0, train_loss_step=2.91e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:01<10:24, 59.38it/s, v_num=0, train_loss_step=5.61e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:24<09:00, 59.41it/s, v_num=0, train_loss_step=5.61e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:24<09:00, 59.41it/s, v_num=0, train_loss_step=3.97e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:48<07:35, 59.44it/s, v_num=0, train_loss_step=3.97e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:48<07:35, 59.44it/s, v_num=0, train_loss_step=8.33e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:12<06:11, 59.45it/s, v_num=0, train_loss_step=8.33e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:12<06:11, 59.45it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:36<04:47, 59.46it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:36<04:47, 59.46it/s, v_num=0, train_loss_step=2.19e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:00<03:23, 59.48it/s, v_num=0, train_loss_step=2.19e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:00<03:23, 59.48it/s, v_num=0, train_loss_step=1.9e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6] Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:24<01:59, 59.48it/s, v_num=0, train_loss_step=1.9e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:24<01:59, 59.48it/s, v_num=0, train_loss_step=3.27e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:48<00:35, 59.49it/s, v_num=0, train_loss_step=3.27e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:48<00:35, 59.49it/s, v_num=0, train_loss_step=1.09e-5, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:23<00:00, 59.49it/s, v_num=0, train_loss_step=1.09e-5, val_loss=5.74e-6, train_loss_epoch=5.85e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:23<00:00, 59.49it/s, v_num=0, train_loss_step=2e-6, val_loss=5.74e-6, train_loss_epoch=5.85e-6]   
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:59<01:38, 83.41it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:59<00:38, 83.74it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:37<00:00, 83.82it/s][A
                                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:01<00:00, 51.69it/s, v_num=0, train_loss_step=2e-6, val_loss=4.73e-6, train_loss_epoch=5.85e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:01<00:00, 51.69it/s, v_num=0, train_loss_step=2e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]            Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:26<16:33, 57.48it/s, v_num=0, train_loss_step=2e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:26<16:33, 57.48it/s, v_num=0, train_loss_step=8.64e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [02:52<15:00, 57.84it/s, v_num=0, train_loss_step=8.64e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [02:52<15:00, 57.84it/s, v_num=0, train_loss_step=5.51e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:19<13:35, 57.72it/s, v_num=0, train_loss_step=5.51e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:19<13:35, 57.72it/s, v_num=0, train_loss_step=1.96e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:46<12:09, 57.67it/s, v_num=0, train_loss_step=1.96e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:46<12:09, 57.67it/s, v_num=0, train_loss_step=3.75e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:13<10:43, 57.61it/s, v_num=0, train_loss_step=3.75e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:13<10:43, 57.61it/s, v_num=0, train_loss_step=2.39e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:40<09:16, 57.63it/s, v_num=0, train_loss_step=2.39e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:40<09:16, 57.63it/s, v_num=0, train_loss_step=4.44e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:07<07:49, 57.65it/s, v_num=0, train_loss_step=4.44e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:07<07:49, 57.65it/s, v_num=0, train_loss_step=4.03e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:34<06:23, 57.61it/s, v_num=0, train_loss_step=4.03e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:34<06:23, 57.61it/s, v_num=0, train_loss_step=3.87e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:00<04:56, 57.67it/s, v_num=0, train_loss_step=3.87e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:00<04:56, 57.67it/s, v_num=0, train_loss_step=4.33e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:26<03:29, 57.69it/s, v_num=0, train_loss_step=4.33e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:26<03:29, 57.69it/s, v_num=0, train_loss_step=2.84e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:53<02:02, 57.69it/s, v_num=0, train_loss_step=2.84e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:53<02:02, 57.69it/s, v_num=0, train_loss_step=1.95e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:20<00:36, 57.68it/s, v_num=0, train_loss_step=1.95e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [17:20<00:36, 57.68it/s, v_num=0, train_loss_step=3.04e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:56<00:00, 57.68it/s, v_num=0, train_loss_step=3.04e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:56<00:00, 57.68it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.73e-6, train_loss_epoch=5.63e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:01<01:40, 81.38it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:02<00:39, 81.66it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:41<00:00, 81.62it/s][A
                                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:38<00:00, 50.14it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.87e-6, train_loss_epoch=5.63e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:38<00:00, 50.14it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]            Epoch 6:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:28<16:48, 56.61it/s, v_num=0, train_loss_step=4.07e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:28<16:48, 56.61it/s, v_num=0, train_loss_step=2.26e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [02:55<15:14, 56.94it/s, v_num=0, train_loss_step=2.26e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [02:55<15:14, 56.94it/s, v_num=0, train_loss_step=1.87e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:23<13:45, 57.03it/s, v_num=0, train_loss_step=1.87e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:23<13:45, 57.03it/s, v_num=0, train_loss_step=5.82e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:50<12:17, 57.03it/s, v_num=0, train_loss_step=5.82e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:50<12:17, 57.03it/s, v_num=0, train_loss_step=2.82e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:17<10:49, 57.14it/s, v_num=0, train_loss_step=2.82e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:17<10:49, 57.14it/s, v_num=0, train_loss_step=1.91e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:45<09:21, 57.12it/s, v_num=0, train_loss_step=1.91e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:45<09:21, 57.12it/s, v_num=0, train_loss_step=3.38e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:11<07:53, 57.20it/s, v_num=0, train_loss_step=3.38e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:11<07:53, 57.20it/s, v_num=0, train_loss_step=1.69e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:38<06:25, 57.23it/s, v_num=0, train_loss_step=1.69e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:38<06:25, 57.23it/s, v_num=0, train_loss_step=9.45e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:02<06:38, 55.37it/s, v_num=0, train_loss_step=9.45e-6, val_loss=4.87e-6, train_loss_epoch=5.67e-6]
------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23467228: <_transf_test> in cluster <dcc> Exited

Job <_transf_test> was submitted from host <hpclogin1> by user <s194262> in cluster <dcc> at Wed Dec 18 11:13:24 2024
Job was executed on host(s) <4*n-62-20-10>, in queue <gpuv100>, as user <s194262> in cluster <dcc> at Wed Dec 18 13:32:14 2024
</zhome/96/8/147177> was used as the home directory.
</work3/s194262/GitHub/fault_management_uds> was used as the working directory.
Started at Wed Dec 18 13:32:14 2024
Terminated at Wed Dec 18 15:46:44 2024
Results reported at Wed Dec 18 15:46:44 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh 

### -- set the job Name --
#BSUB -J _transf_test
### -- specify files --
#BSUB -o /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J-_transf_test.out
#BSUB -e /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J-_transf_test.err

### General options
### â€“- specify queue --
#BSUB -q gpuv100
### -- ask for number of cores (default: 1) --
#BSUB -n 4
### -- Select the resources: 1 gpu in exclusive process mode --
#BSUB -gpu "num=1:mode=exclusive_process"
### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now
#BSUB -W 24:00
### -- request _ GB of system-memory --
#BSUB -R "rusage[mem=4GB]"
#BSUB -R "span[hosts=1]"


nvidia-smi
module load cuda/11.8

source /work3/s194262/thesis/bin/activate

cd /work3/s194262/GitHub/fault_management_uds

python fault_management_uds/main.py --config "transformer/testing.yaml" --num_workers 0



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   7610.00 sec.
    Max Memory :                                 2720 MB
    Average Memory :                             2650.48 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13664.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                12
    Run time :                                   8071 sec.
    Turnaround time :                            16400 sec.

The output (if any) is above this job summary.



PS:

Read file </work3/s194262/GitHub/fault_management_uds/hpc_logs/23467228-_transf_test.err> for stderr output of this job.


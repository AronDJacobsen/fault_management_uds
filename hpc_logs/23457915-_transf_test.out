Wed Dec 18 08:35:39 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:37:00.0 Off |                    0 |
| N/A   56C    P0             33W /  250W |       1MiB /  16384MiB |      0%   E. Process |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Warning: ['training_args', 'lr'] is not a list; must be for hparam search
Warning: ['model_args', 'hidden_size'] is not a list; must be for hparam search
Warning: ['model_args', 'num_heads'] is not a list; must be for hparam search
Warning: ['model_args', 'num_layers'] is not a list; must be for hparam search

##################################################
EXPERIMENT 1/1
Save folder: /work3/s194262/GitHub/fault_management_uds/models/transformer/lr=0.0005_hidden_size=64_num_heads=2_num_layers=2_241218_0836

Hyperparameters: {'training_args/lr': 0.0005, 'model_args/hidden_size': 64, 'model_args/num_heads': 2, 'model_args/num_layers': 2}
##################################################

Validity: 94418 minutes are invalid.
Data validation passed.
Model does not have additional configurations.
Using CUDA
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.97it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/62089 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s] Epoch 0:   8%|â–Š         | 5000/62089 [01:26<16:30, 57.62it/s]Epoch 0:   8%|â–Š         | 5000/62089 [01:26<16:30, 57.62it/s, v_num=0, train_loss_step=1.02e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [02:51<14:51, 58.41it/s, v_num=0, train_loss_step=1.02e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [02:51<14:51, 58.41it/s, v_num=0, train_loss_step=2.91e-6]Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:15<13:22, 58.71it/s, v_num=0, train_loss_step=2.91e-6]Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:15<13:22, 58.71it/s, v_num=0, train_loss_step=5.91e-5]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:39<11:54, 58.90it/s, v_num=0, train_loss_step=5.91e-5]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:39<11:54, 58.90it/s, v_num=0, train_loss_step=1.03e-5]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:04<10:29, 58.96it/s, v_num=0, train_loss_step=1.03e-5]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:04<10:29, 58.96it/s, v_num=0, train_loss_step=2.83e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:28<09:03, 59.05it/s, v_num=0, train_loss_step=2.83e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:28<09:03, 59.05it/s, v_num=0, train_loss_step=4.45e-6]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:52<07:38, 59.08it/s, v_num=0, train_loss_step=4.45e-6]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:52<07:38, 59.08it/s, v_num=0, train_loss_step=2.5e-6] Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:16<06:13, 59.12it/s, v_num=0, train_loss_step=2.5e-6]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:16<06:13, 59.12it/s, v_num=0, train_loss_step=9.75e-6]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:41<04:49, 59.12it/s, v_num=0, train_loss_step=9.75e-6]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:41<04:49, 59.12it/s, v_num=0, train_loss_step=3.62e-6]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:06<03:24, 59.09it/s, v_num=0, train_loss_step=3.62e-6]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:06<03:24, 59.09it/s, v_num=0, train_loss_step=1.58e-5]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:31<02:00, 59.07it/s, v_num=0, train_loss_step=1.58e-5]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:31<02:00, 59.07it/s, v_num=0, train_loss_step=2.33e-5]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:56<00:35, 59.04it/s, v_num=0, train_loss_step=2.33e-5]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:56<00:35, 59.04it/s, v_num=0, train_loss_step=5.95e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:31<00:00, 59.03it/s, v_num=0, train_loss_step=5.95e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:31<00:00, 59.03it/s, v_num=0, train_loss_step=2.23e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:33, 87.76it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:53<00:36, 87.85it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:30<00:00, 87.85it/s][A
                                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:02<00:00, 51.65it/s, v_num=0, train_loss_step=2.23e-6, val_loss=5.56e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [20:02<00:00, 51.65it/s, v_num=0, train_loss_step=2.23e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]            Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:24<16:09, 58.89it/s, v_num=0, train_loss_step=2.23e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:24<16:09, 58.89it/s, v_num=0, train_loss_step=3.04e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:39, 59.21it/s, v_num=0, train_loss_step=3.04e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:39, 59.21it/s, v_num=0, train_loss_step=4.32e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:13<13:14, 59.24it/s, v_num=0, train_loss_step=4.32e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:13<13:14, 59.24it/s, v_num=0, train_loss_step=2.91e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:37<11:50, 59.27it/s, v_num=0, train_loss_step=2.91e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:37<11:50, 59.27it/s, v_num=0, train_loss_step=1.04e-5, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:01<10:25, 59.31it/s, v_num=0, train_loss_step=1.04e-5, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:01<10:25, 59.31it/s, v_num=0, train_loss_step=4.47e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:25<09:00, 59.32it/s, v_num=0, train_loss_step=4.47e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:25<09:00, 59.32it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:49<07:36, 59.34it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:49<07:36, 59.34it/s, v_num=0, train_loss_step=6.66e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:14<06:12, 59.33it/s, v_num=0, train_loss_step=6.66e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:14<06:12, 59.33it/s, v_num=0, train_loss_step=5.19e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:38<04:48, 59.33it/s, v_num=0, train_loss_step=5.19e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:38<04:48, 59.33it/s, v_num=0, train_loss_step=3.53e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:02<03:23, 59.33it/s, v_num=0, train_loss_step=3.53e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [14:02<03:23, 59.33it/s, v_num=0, train_loss_step=4.45e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:26<01:59, 59.35it/s, v_num=0, train_loss_step=4.45e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:26<01:59, 59.35it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:50<00:35, 59.38it/s, v_num=0, train_loss_step=3.43e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:50<00:35, 59.38it/s, v_num=0, train_loss_step=3.64e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:25<00:00, 59.40it/s, v_num=0, train_loss_step=3.64e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:25<00:00, 59.40it/s, v_num=0, train_loss_step=8.48e-6, val_loss=5.56e-6, train_loss_epoch=9.14e-5]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:32, 88.22it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:53<00:36, 88.12it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:29<00:00, 88.10it/s][A
                                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:55<00:00, 51.95it/s, v_num=0, train_loss_step=8.48e-6, val_loss=4.39e-6, train_loss_epoch=9.14e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:55<00:00, 51.95it/s, v_num=0, train_loss_step=8.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=8.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]            Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=8.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:23<15:55, 59.78it/s, v_num=0, train_loss_step=8.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:23<15:55, 59.78it/s, v_num=0, train_loss_step=3.85e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [02:46<14:28, 59.98it/s, v_num=0, train_loss_step=3.85e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [02:46<14:28, 59.98it/s, v_num=0, train_loss_step=3.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:09<13:03, 60.10it/s, v_num=0, train_loss_step=3.48e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:09<13:03, 60.10it/s, v_num=0, train_loss_step=9.58e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:32<11:39, 60.20it/s, v_num=0, train_loss_step=9.58e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:32<11:39, 60.20it/s, v_num=0, train_loss_step=3.52e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:55<10:15, 60.22it/s, v_num=0, train_loss_step=3.52e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:55<10:15, 60.22it/s, v_num=0, train_loss_step=1.8e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6] Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:18<08:53, 60.17it/s, v_num=0, train_loss_step=1.8e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:18<08:53, 60.17it/s, v_num=0, train_loss_step=7.82e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:42<07:30, 60.10it/s, v_num=0, train_loss_step=7.82e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:42<07:30, 60.10it/s, v_num=0, train_loss_step=1.24e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:05<06:07, 60.12it/s, v_num=0, train_loss_step=1.24e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:05<06:07, 60.12it/s, v_num=0, train_loss_step=2.49e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:28<04:44, 60.10it/s, v_num=0, train_loss_step=2.49e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:28<04:44, 60.10it/s, v_num=0, train_loss_step=8.16e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:52<03:21, 60.04it/s, v_num=0, train_loss_step=8.16e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:52<03:21, 60.04it/s, v_num=0, train_loss_step=6.03e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:16<01:58, 60.00it/s, v_num=0, train_loss_step=6.03e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:16<01:58, 60.00it/s, v_num=0, train_loss_step=2.41e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:40<00:34, 59.97it/s, v_num=0, train_loss_step=2.41e-6, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:40<00:34, 59.97it/s, v_num=0, train_loss_step=1.52e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:15<00:00, 59.96it/s, v_num=0, train_loss_step=1.52e-5, val_loss=4.39e-6, train_loss_epoch=7.08e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:15<00:00, 59.96it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.39e-6, train_loss_epoch=7.08e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:57<01:33, 87.42it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:54<00:36, 87.47it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:30<00:00, 87.50it/s][A
                                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:46<00:00, 52.33it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.81e-6, train_loss_epoch=7.08e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:46<00:00, 52.33it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.81e-6, train_loss_epoch=6.53e-6]            Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:24<16:08, 58.94it/s, v_num=0, train_loss_step=9.39e-7, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:24<16:08, 58.94it/s, v_num=0, train_loss_step=2.18e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:35, 59.47it/s, v_num=0, train_loss_step=2.18e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [02:48<14:35, 59.47it/s, v_num=0, train_loss_step=7.8e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6] Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:10<13:07, 59.78it/s, v_num=0, train_loss_step=7.8e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:10<13:07, 59.78it/s, v_num=0, train_loss_step=3.64e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:33<11:42, 59.89it/s, v_num=0, train_loss_step=3.64e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:33<11:42, 59.89it/s, v_num=0, train_loss_step=2.98e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:57<10:19, 59.91it/s, v_num=0, train_loss_step=2.98e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:57<10:19, 59.91it/s, v_num=0, train_loss_step=7.15e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:20<08:55, 59.89it/s, v_num=0, train_loss_step=7.15e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:20<08:55, 59.88it/s, v_num=0, train_loss_step=2.1e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6] Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:44<07:32, 59.88it/s, v_num=0, train_loss_step=2.1e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:44<07:32, 59.88it/s, v_num=0, train_loss_step=2.59e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:08<06:09, 59.85it/s, v_num=0, train_loss_step=2.59e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:08<06:09, 59.85it/s, v_num=0, train_loss_step=5.38e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:31<04:45, 59.88it/s, v_num=0, train_loss_step=5.38e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:31<04:45, 59.88it/s, v_num=0, train_loss_step=6.67e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:54<03:21, 59.91it/s, v_num=0, train_loss_step=6.67e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:54<03:21, 59.91it/s, v_num=0, train_loss_step=2.33e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:18<01:58, 59.89it/s, v_num=0, train_loss_step=2.33e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:18<01:58, 59.89it/s, v_num=0, train_loss_step=1.05e-5, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:41<00:34, 59.90it/s, v_num=0, train_loss_step=1.05e-5, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:41<00:34, 59.90it/s, v_num=0, train_loss_step=6.6e-5, val_loss=4.81e-6, train_loss_epoch=6.53e-6] Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:16<00:00, 59.88it/s, v_num=0, train_loss_step=6.6e-5, val_loss=4.81e-6, train_loss_epoch=6.53e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:16<00:00, 59.88it/s, v_num=0, train_loss_step=4.16e-6, val_loss=4.81e-6, train_loss_epoch=6.53e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:32, 88.60it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:53<00:36, 88.46it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:29<00:00, 88.46it/s][A
                                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:46<00:00, 52.35it/s, v_num=0, train_loss_step=4.16e-6, val_loss=7.42e-6, train_loss_epoch=6.53e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:46<00:00, 52.35it/s, v_num=0, train_loss_step=4.16e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]            Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:24<16:01, 59.35it/s, v_num=0, train_loss_step=4.16e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:24<16:01, 59.35it/s, v_num=0, train_loss_step=6.86e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [02:46<14:29, 59.89it/s, v_num=0, train_loss_step=6.86e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [02:46<14:29, 59.89it/s, v_num=0, train_loss_step=6.88e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:09<13:04, 60.04it/s, v_num=0, train_loss_step=6.88e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:09<13:04, 60.04it/s, v_num=0, train_loss_step=1.89e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:33<11:41, 60.03it/s, v_num=0, train_loss_step=1.89e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:33<11:41, 60.03it/s, v_num=0, train_loss_step=3.22e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:56<10:17, 60.07it/s, v_num=0, train_loss_step=3.22e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:56<10:17, 60.07it/s, v_num=0, train_loss_step=2.03e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:19<08:54, 60.09it/s, v_num=0, train_loss_step=2.03e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:19<08:54, 60.09it/s, v_num=0, train_loss_step=2.12e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:42<07:30, 60.12it/s, v_num=0, train_loss_step=2.12e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:42<07:30, 60.12it/s, v_num=0, train_loss_step=2.9e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6] Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:04<06:06, 60.20it/s, v_num=0, train_loss_step=2.9e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:04<06:06, 60.20it/s, v_num=0, train_loss_step=4.72e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:27<04:43, 60.19it/s, v_num=0, train_loss_step=4.72e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:27<04:43, 60.19it/s, v_num=0, train_loss_step=2.44e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:50<03:20, 60.22it/s, v_num=0, train_loss_step=2.44e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:50<03:20, 60.22it/s, v_num=0, train_loss_step=3.8e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6] Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:12<01:57, 60.24it/s, v_num=0, train_loss_step=3.8e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:12<01:57, 60.24it/s, v_num=0, train_loss_step=4.81e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:35<00:34, 60.28it/s, v_num=0, train_loss_step=4.81e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:35<00:34, 60.28it/s, v_num=0, train_loss_step=4.27e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:09<00:00, 60.30it/s, v_num=0, train_loss_step=4.27e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:09<00:00, 60.30it/s, v_num=0, train_loss_step=4.97e-6, val_loss=7.42e-6, train_loss_epoch=6.31e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:32, 88.88it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:52<00:36, 88.88it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:28<00:00, 88.87it/s][A
                                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:38<00:00, 52.70it/s, v_num=0, train_loss_step=4.97e-6, val_loss=1.03e-5, train_loss_epoch=6.31e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:38<00:00, 52.70it/s, v_num=0, train_loss_step=4.97e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]            Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:23<15:51, 60.01it/s, v_num=0, train_loss_step=4.97e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:23<15:51, 60.01it/s, v_num=0, train_loss_step=3.25e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [02:45<14:24, 60.25it/s, v_num=0, train_loss_step=3.25e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [02:45<14:24, 60.25it/s, v_num=0, train_loss_step=2.78e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:08<13:00, 60.34it/s, v_num=0, train_loss_step=2.78e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:08<13:00, 60.34it/s, v_num=0, train_loss_step=3.61e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:30<11:36, 60.42it/s, v_num=0, train_loss_step=3.61e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:30<11:36, 60.42it/s, v_num=0, train_loss_step=2.95e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:53<10:13, 60.42it/s, v_num=0, train_loss_step=2.95e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:53<10:13, 60.42it/s, v_num=0, train_loss_step=1.76e-5, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:17<08:51, 60.34it/s, v_num=0, train_loss_step=1.76e-5, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:17<08:51, 60.34it/s, v_num=0, train_loss_step=2.04e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:40<07:28, 60.34it/s, v_num=0, train_loss_step=2.04e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:40<07:28, 60.34it/s, v_num=0, train_loss_step=3.53e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:02<06:06, 60.34it/s, v_num=0, train_loss_step=3.53e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:02<06:06, 60.34it/s, v_num=0, train_loss_step=2.56e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:25<04:43, 60.35it/s, v_num=0, train_loss_step=2.56e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:25<04:43, 60.35it/s, v_num=0, train_loss_step=2.89e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:48<03:20, 60.37it/s, v_num=0, train_loss_step=2.89e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:48<03:20, 60.37it/s, v_num=0, train_loss_step=3.26e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:10<01:57, 60.37it/s, v_num=0, train_loss_step=3.26e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:10<01:57, 60.37it/s, v_num=0, train_loss_step=3.62e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:33<00:34, 60.42it/s, v_num=0, train_loss_step=3.62e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:33<00:34, 60.42it/s, v_num=0, train_loss_step=3.49e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:07<00:00, 60.43it/s, v_num=0, train_loss_step=3.49e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:07<00:00, 60.43it/s, v_num=0, train_loss_step=1.83e-6, val_loss=1.03e-5, train_loss_epoch=6.02e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:32, 88.78it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:52<00:36, 88.77it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:28<00:00, 88.79it/s][A
                                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:36<00:00, 52.79it/s, v_num=0, train_loss_step=1.83e-6, val_loss=9.83e-6, train_loss_epoch=6.02e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:36<00:00, 52.79it/s, v_num=0, train_loss_step=1.83e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]            Epoch 6:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:24<16:00, 59.44it/s, v_num=0, train_loss_step=1.83e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:24<16:00, 59.44it/s, v_num=0, train_loss_step=3.21e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [02:47<14:30, 59.82it/s, v_num=0, train_loss_step=3.21e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [02:47<14:30, 59.82it/s, v_num=0, train_loss_step=5.88e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:10<13:05, 59.96it/s, v_num=0, train_loss_step=5.88e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:10<13:05, 59.96it/s, v_num=0, train_loss_step=4.33e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:32<11:40, 60.10it/s, v_num=0, train_loss_step=4.33e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [05:32<11:40, 60.10it/s, v_num=0, train_loss_step=7.34e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:55<10:15, 60.21it/s, v_num=0, train_loss_step=7.34e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [06:55<10:15, 60.21it/s, v_num=0, train_loss_step=2.78e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:17<08:52, 60.28it/s, v_num=0, train_loss_step=2.78e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [08:17<08:52, 60.27it/s, v_num=0, train_loss_step=4.41e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:40<07:29, 60.29it/s, v_num=0, train_loss_step=4.41e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [09:40<07:29, 60.29it/s, v_num=0, train_loss_step=7.29e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:03<06:06, 60.29it/s, v_num=0, train_loss_step=7.29e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [11:03<06:06, 60.29it/s, v_num=0, train_loss_step=4.71e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:26<04:43, 60.26it/s, v_num=0, train_loss_step=4.71e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [12:26<04:43, 60.26it/s, v_num=0, train_loss_step=4.56e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:50<03:20, 60.24it/s, v_num=0, train_loss_step=4.56e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [13:50<03:20, 60.24it/s, v_num=0, train_loss_step=2.52e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:13<01:57, 60.23it/s, v_num=0, train_loss_step=2.52e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [15:13<01:57, 60.23it/s, v_num=0, train_loss_step=5.43e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:36<00:34, 60.23it/s, v_num=0, train_loss_step=5.43e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [16:36<00:34, 60.23it/s, v_num=0, train_loss_step=4.68e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:11<00:00, 60.21it/s, v_num=0, train_loss_step=4.68e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [17:11<00:00, 60.21it/s, v_num=0, train_loss_step=3.01e-6, val_loss=9.83e-6, train_loss_epoch=5.99e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [00:56<01:32, 88.19it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [01:51<00:35, 89.50it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:27<00:00, 89.70it/s][A
                                                                              [AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:38<00:00, 52.69it/s, v_num=0, train_loss_step=3.01e-6, val_loss=1.13e-5, train_loss_epoch=5.99e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:38<00:00, 52.69it/s, v_num=0, train_loss_step=3.01e-6, val_loss=1.13e-5, train_loss_epoch=5.65e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:38<00:00, 52.69it/s, v_num=0, train_loss_step=3.01e-6, val_loss=1.13e-5, train_loss_epoch=5.65e-6]
Using CUDA
Model loaded from /work3/s194262/GitHub/fault_management_uds/models/transformer/lr=0.0005_hidden_size=64_num_heads=2_num_layers=2_241218_0836/1_split/epoch=01-val_loss=0.0000044.ckpt
Loggers: dict_keys(['train_loss_step', 'epoch', 'val_loss', 'train_loss_epoch'])

Run lr=0.0005_hidden_size=64_num_heads=2_num_layers=2_241218_0836 completed



------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23457915: <_transf_test> in cluster <dcc> Done

Job <_transf_test> was submitted from host <hpclogin1> by user <s194262> in cluster <dcc> at Wed Dec 18 08:35:36 2024
Job was executed on host(s) <4*n-62-20-3>, in queue <gpuv100>, as user <s194262> in cluster <dcc> at Wed Dec 18 08:35:37 2024
</zhome/96/8/147177> was used as the home directory.
</work3/s194262/GitHub/fault_management_uds> was used as the working directory.
Started at Wed Dec 18 08:35:37 2024
Terminated at Wed Dec 18 11:04:41 2024
Results reported at Wed Dec 18 11:04:41 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh 

### -- set the job Name --
#BSUB -J _transf_test
### -- specify files --
#BSUB -o /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J-_transf_test.out
#BSUB -e /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J-_transf_test.err

### General options
### â€“- specify queue --
#BSUB -q gpuv100
### -- ask for number of cores (default: 1) --
#BSUB -n 4
### -- Select the resources: 1 gpu in exclusive process mode --
#BSUB -gpu "num=1:mode=exclusive_process"
### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now
#BSUB -W 24:00
### -- request _ GB of system-memory --
#BSUB -R "rusage[mem=4GB]"
#BSUB -R "span[hosts=1]"


nvidia-smi
module load cuda/11.8

source /work3/s194262/thesis/bin/activate

cd /work3/s194262/GitHub/fault_management_uds

python fault_management_uds/main.py --config "transformer/testing.yaml" --num_workers 0



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8469.00 sec.
    Max Memory :                                 3423 MB
    Average Memory :                             2737.03 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               12961.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                12
    Run time :                                   9052 sec.
    Turnaround time :                            8945 sec.

The output (if any) is above this job summary.



PS:

Read file </work3/s194262/GitHub/fault_management_uds/hpc_logs/23457915-_transf_test.err> for stderr output of this job.


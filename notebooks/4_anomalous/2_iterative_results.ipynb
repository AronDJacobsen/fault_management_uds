{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fault_management_uds.config import PROJ_ROOT\n",
    "from fault_management_uds.config import DATA_DIR, RAW_DATA_DIR, INTERIM_DATA_DIR, PROCESSED_DATA_DIR, EXTERNAL_DATA_DIR\n",
    "from fault_management_uds.config import MODELS_DIR, REPORTS_DIR, FIGURES_DIR, REFERENCE_DIR\n",
    "from fault_management_uds.config import rain_gauge_color, condition_to_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_2_data_label = json.load(open(REFERENCE_DIR / 'indicator_2_data_label.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_types = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "data_type = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iterations folders\n",
    "save_folder = \"transformer/7_anomalous\"\n",
    "save_folder = MODELS_DIR / save_folder\n",
    "prefix = \"iteration=\"\n",
    "\n",
    "relative_path = \"1_split/anomalous\"\n",
    "\n",
    "filename = 'anomaly_prediction_results.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_outputs(outputs):\n",
    "    data_label = outputs[\"data_label\"]\n",
    "    # true is where data_label is not 'Original'\n",
    "    true = data_label != 'Original'\n",
    "    decision_function = outputs[\"decision_function\"]\n",
    "\n",
    "    idx_pred_0 = outputs['0']\n",
    "    label_0 = np.zeros(len(idx_pred_0), dtype=int)\n",
    "    idx_pred_1 = outputs['1']\n",
    "    label_1 = np.ones(len(idx_pred_1), dtype=int)\n",
    "\n",
    "    # align these predictions with the true labels\n",
    "    idx_pred = np.concatenate((idx_pred_0, idx_pred_1))\n",
    "    label_pred = np.concatenate((label_0, label_1))\n",
    "\n",
    "    # sort the predictions\n",
    "    sort_indices = np.argsort(idx_pred)\n",
    "    idx_pred = idx_pred[sort_indices]\n",
    "    label_pred = label_pred[sort_indices]\n",
    "\n",
    "    return idx_pred, label_pred, decision_function, true, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "Highest iteration: 3\n",
      "['iteration=0_250106_0752', 'iteration=0.1_250107_1455', 'iteration=0.1.0_250108_2222', 'iteration=0.0.1_250108_2105', 'iteration=0.0_250107_1459', 'iteration=0.1.1_250108_2117', 'iteration=0.0.0_250108_2052']\n",
      "Iteration identifier: 0\n",
      "Number of iteration: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "runs = os.listdir(save_folder)\n",
    "runs = [run for run in runs if run.startswith(prefix)]\n",
    "print(f\"Total: {len(runs)}\")\n",
    "# take ceil of log2 of the number of runs to get the highest iteration\n",
    "n_iterations = int(np.ceil(np.log2(len(runs))))\n",
    "print(f\"Highest iteration: {n_iterations}\")\n",
    "\n",
    "print(runs)\n",
    "\n",
    "combined_results = {\n",
    "}\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    combined_results[str(iteration)] = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for run in runs:\n",
    "    # get the iteration number\n",
    "    iteration_identifier = run.split(\"=\")[-1].split(\"_\")[0]\n",
    "    print(f\"Iteration identifier: {iteration_identifier}\")\n",
    "    n_iteration = len(iteration_identifier.split(\".\"))\n",
    "    print(f\"Number of iteration: {n_iteration}\")\n",
    "\n",
    "    # load the outputs file\n",
    "    outputs_file = save_folder / run / relative_path / data_type / filename\n",
    "    outputs = pd.read_pickle(outputs_file)\n",
    "\n",
    "    idx_pred, label_pred, decision_function, true, data_label = extract_outputs(outputs)\n",
    "    del outputs\n",
    "    break\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

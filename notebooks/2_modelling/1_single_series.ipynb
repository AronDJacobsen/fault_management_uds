{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Series modelling\n",
    "\n",
    "*Masked Multi-Step Autoregressive Regression*\n",
    "\n",
    "\n",
    "#### Contents\n",
    "\n",
    "1. [Dataset](#1)\n",
    "2. [Model](#2)\n",
    "3. [Training](#3)\n",
    "4. [Evaluation](#4)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial design choices:\n",
    "- *Autoregressive*: predict the next value based on the previous values.\n",
    "- *Masking*: mask to predict the the last 1 minute of the sensor and rain data.\n",
    "- *Normalize*: normalize the data to a range of 0.1-1, and mask missing values with 0.\n",
    "- *Loss function*: mask missing values.\n",
    "- *Sliding window*: use a sliding window of # minutes to predict the next 1 minute for better comparison with the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible experiments\n",
    "\n",
    "- Predict residuals/changes\n",
    "- Multi-step-ahead scheduling\n",
    "- Quantiles?\n",
    "- Data augmentation\n",
    "- Utilize Mike predictions for training or evaluation\n",
    "- Alternate masking for multi-sensor and comparison?\n",
    "- 1-minute masking or 5-minute masking, or alternate?\n",
    "- include both rainfall sensors?\n",
    "- train on multistep ahead predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### TODO:\n",
    "\n",
    "- figures wrt masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 14:36:16.156 | INFO     | fault_management_uds.config:<module>:11 - PROJ_ROOT path is: /Users/arond.jacobsen/Documents/GitHub/fault_management_uds\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import yaml\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from fault_management_uds.data.hdf_functions import print_tree, load_dataframe_from_HDF5\n",
    "from fault_management_uds.data.process import remove_nans_from_start_end\n",
    "from fault_management_uds.config import indicator_2_meta, bools_2_meta, error_indicators, natural_sensor_order\n",
    "from fault_management_uds.data.load import import_external_metadata, import_metadata\n",
    "from fault_management_uds.data.format import merge_intervals\n",
    "from fault_management_uds.plots import get_segment_start_end_color, set_meaningful_xticks\n",
    "\n",
    "\n",
    "from fault_management_uds.utilities import get_accelerator\n",
    "from fault_management_uds.data.dataset import get_datasets, handle_splits\n",
    "from fault_management_uds.data.load import load_data\n",
    "\n",
    "from fault_management_uds.modelling.models import get_model\n",
    "\n",
    "\n",
    "from fault_management_uds.config import PROJ_ROOT\n",
    "from fault_management_uds.config import DATA_DIR, RAW_DATA_DIR, INTERIM_DATA_DIR, PROCESSED_DATA_DIR, EXTERNAL_DATA_DIR\n",
    "from fault_management_uds.config import MODELS_DIR, REPORTS_DIR, FIGURES_DIR, REFERENCE_DIR\n",
    "from fault_management_uds.config import rain_gauge_color, rain_gauges\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = PROCESSED_DATA_DIR / 'Bellinge.h5'\n",
    "external_metadata = import_metadata(REFERENCE_DIR / 'external_metadata.csv')\n",
    "metadata = import_metadata(REFERENCE_DIR / 'sensor_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the obvious min dict\n",
    "obvious_min_dict = {}\n",
    "for sensor in natural_sensor_order:\n",
    "    obvious_min_dict[sensor] = metadata[metadata['IdMeasurement'] == sensor].iloc[0]['obvious_min']\n",
    "\n",
    "for rain_gauge in rain_gauges:\n",
    "    obvious_min_dict[rain_gauge] = 0.0\n",
    "\n",
    "len(obvious_min_dict)#, obvious_min_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = {\n",
    "    # define the sensors to use\n",
    "    'engineered_vars': ['sin_time', 'cos_time'], # ['time_of_day', 'day_of_week']\n",
    "    'exogenous_vars': ['5425'],\n",
    "    # target\n",
    "    'endogenous_vars': ['G72F040'],\n",
    "\n",
    "    # define priority of rain event, _ times more important than other events\n",
    "    'rain_event_priority': 1.0, # _ times more sampling in data loader\n",
    "\n",
    "    # precision\n",
    "    'precision': 3,\n",
    "\n",
    "    # processing\n",
    "    'function_transform_type': 'log', # ['none', 'log', 'sqrt']\n",
    "    'scaler_type': 'min-max', # ['min-max', 'standard']\n",
    "    'feature_range': (0, 1),  #(0.1, 1),\n",
    "    'nan_value': 0,\n",
    "\n",
    "    # data augmentation\n",
    "    'noise_injection': False,\n",
    "\n",
    "    # dataset\n",
    "    'n_splits': 1,\n",
    "    'train_split': 0.7, \n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "\n",
    "    # model\n",
    "    'sequence_length': 60*3, \n",
    "    'steps_ahead': 1, # 1 minute ahead prediction\n",
    "\n",
    "    # other\n",
    "    'data_file_path': str(data_file_path),\n",
    "\n",
    "}\n",
    "# all variables\n",
    "dataset_args['variable_list'] = dataset_args['engineered_vars'] + dataset_args['exogenous_vars'] + dataset_args['endogenous_vars']\n",
    "# variables within the data loaded\n",
    "dataset_args['data_variables'] = dataset_args['exogenous_vars'] + dataset_args['endogenous_vars']\n",
    "# save relevant obvious min values\n",
    "dataset_args['obvious_min'] = {sensor: obvious_min_dict.get(sensor, 0.0) for sensor in dataset_args['variable_list']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'learning_rate': 0.001,\n",
    "    'loss_function': 'MSELoss', # ['MSELoss', 'MAELoss']\n",
    "    'max_epochs': 30,\n",
    "    'batch_size': 64,\n",
    "    'log_every_n_steps': 1,\n",
    "    # val check every epoch\n",
    "    'val_check_interval': 1.0, # []\n",
    "    # early stopping\n",
    "    'early_stopping_patience': 5,\n",
    "    'seed': seed,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'model_name': 'SimpleNN', # ['SimpleNN', 'LSTM']\n",
    "    'input_size': len(dataset_args['variable_list']),\n",
    "    'sequence_length': dataset_args['sequence_length'],\n",
    "    'output_size': len(dataset_args['endogenous_vars']),\n",
    "    'hidden_size': 16,\n",
    "    'num_layers': 1,\n",
    "    'dropout': 0.0,\n",
    "}\n",
    "\n",
    "experiment_name = 'Time of Day + Log + Min-Max'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a more unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "configuring_parameters = [\n",
    "    'rain_event_priority',\n",
    "    'function_transform_type',\n",
    "    'scaler_type',\n",
    "    'sequence_length',\n",
    "    'learning_rate',\n",
    "    'hidden_size',\n",
    "    'num_layers',\n",
    "]\n",
    "# create a configuration name based on the parameters\n",
    "config_name = ''\n",
    "for parameter in configuring_parameters:\n",
    "    if parameter in dataset_args:\n",
    "        config_name += f\"{parameter}_{dataset_args[parameter]}_\"\n",
    "    elif parameter in training_args:\n",
    "        config_name += f\"{parameter}_{training_args[parameter]}_\"\n",
    "    elif parameter in model_args:\n",
    "        config_name += f\"{parameter}_{model_args[parameter]}_\"\n",
    "\n",
    "config_name = config_name[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- Train the model on the dataset\n",
    "- Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, callbacks, logger, training_args):\n",
    "    accelerator = get_accelerator()\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=training_args['max_epochs'],\n",
    "        #max_steps=1,\n",
    "        log_every_n_steps=training_args['log_every_n_steps'],\n",
    "        val_check_interval=training_args['val_check_interval'],  \n",
    "        check_val_every_n_epoch=1,  # Ensure it evaluates at least once per epoch\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        accelerator=accelerator,\n",
    "        devices=\"auto\",\n",
    "        )\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    return model, callbacks, logger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = MODELS_DIR / model_args['model_name']\n",
    "\n",
    "# clean up directories if they are empty\n",
    "if os.path.exists(model_dir):\n",
    "    # iterate folders\n",
    "    for folder in os.listdir(model_dir):\n",
    "        folder_path = model_dir / folder\n",
    "        # check if folder is empty\n",
    "        if os.path.isdir(folder_path):\n",
    "            if not os.listdir(folder_path):\n",
    "                # remove empty folder\n",
    "                os.rmdir(folder_path)\n",
    "        # it is a file and should be removed\n",
    "        else:\n",
    "            os.remove(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data([None, None], data_file_path, dataset_args, data_type='complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa', 'aaa']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"aaa.aaa\".split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 0 minutes are invalid.\n",
      "Data validation passed.\n",
      "Using MPS\n",
      "Validity: 0 minutes are invalid.\n",
      "Data validation passed.\n",
      "Using MPS\n",
      "Validity: 0 minutes are invalid.\n",
      "Data validation passed.\n",
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arond.jacobsen/anaconda3/envs/thesis/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/arond.jacobsen/Documents/GitHub/fault_management_uds/models/SimpleNN/2024-12-11_14:36/1_split exists and is not empty.\n",
      "\n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | SimpleNNModel | 11.6 K | train\n",
      "------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arond.jacobsen/anaconda3/envs/thesis/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arond.jacobsen/anaconda3/envs/thesis/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1182/1182 [03:28<00:00,  5.67it/s, train_loss_step=5.96e-5, val_loss=5.25e-5, train_loss_epoch=7.93e-5]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation: 100%|██████████| 1/1 [1:05:56<00:00, 3956.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create new folder\n",
    "save_folder = model_dir / time.strftime(\"%Y-%m-%d_%H:%M\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# get the splits\n",
    "n_obs = len(data)\n",
    "splits = handle_splits(n_obs, dataset_args)\n",
    "\n",
    "# create folders for each split\n",
    "split_folders = [save_folder / f\"{i+1}_split\" for i in range(dataset_args['n_splits'])]\n",
    "for folder in split_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# save the configs\n",
    "configs = {\n",
    "    'experiment_name': experiment_name,\n",
    "    'config_name': config_name,\n",
    "    'save_folder': str(save_folder),\n",
    "    'dataset_args': dataset_args,\n",
    "    'training_args': training_args,\n",
    "    'model_args': model_args,\n",
    "    'split_folders': [str(folder) for folder in split_folders],\n",
    "}\n",
    "# save as json\n",
    "with open(save_folder / 'configs.json', 'w') as f:\n",
    "    json.dump(configs, f, indent=4)\n",
    "\n",
    "\n",
    "split_info = []\n",
    "for i, (train_index, val_index, test_index) in enumerate(tqdm(splits, desc='Cross-validation', total=len(splits))):\n",
    "    # Paths\n",
    "    current_save_folder = split_folders[i]\n",
    "    start_time = time.time()   \n",
    "\n",
    "    ### Prepare data\n",
    "    train_dataset, val_dataset, _, dataset_config = get_datasets(data, train_index, val_index, test_index, dataset_args)\n",
    "    # create loader\n",
    "    sampler = WeightedRandomSampler(train_dataset.priority_weight, len(train_dataset), replacement=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=training_args['batch_size'], sampler=sampler, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=training_args['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "    # Get model\n",
    "    model = get_model(model_args, training_args)\n",
    "\n",
    "    # Define callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=current_save_folder, filename=\"{epoch:02d}-{val_loss:.5f}\", save_last=True,\n",
    "        monitor=\"val_loss\", save_top_k=1, mode=\"min\",\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=training_args['early_stopping_patience'], mode=\"min\", verbose=False)\n",
    "    callbacks = [checkpoint_callback, early_stopping]\n",
    "    # logger\n",
    "    logger = TensorBoardLogger(current_save_folder, sub_dir='tensorboard', name='', version='', default_hp_metric=False)\n",
    "\n",
    "    # train model\n",
    "    model, callbacks, logger = train_model(model, train_loader, val_loader, callbacks, logger, training_args)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    # save the run info\n",
    "    run_info = {\n",
    "        'save_folder': str(current_save_folder),\n",
    "        'best_model_path': callbacks[0].best_model_path,\n",
    "        'last_model_path': callbacks[0].last_model_path,\n",
    "        'top_k_best_model_paths': callbacks[0].best_k_models,\n",
    "        'dataset_config': dataset_config,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "    split_info.append(run_info)\n",
    "\n",
    "# save the split info\n",
    "with open(save_folder / 'split_info.pkl', 'wb') as f:\n",
    "    pickle.dump(split_info, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training done",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# load \u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Training done"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"Training done\")\n",
    "# load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=models/LSTM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of baseline models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAEs.loc[(1, 'Overall'), 'Overall']\n",
    "# Previous value predictor MAE: 0.0010530973451327434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-02-29T23:40:00.000000000', '2020-02-29T23:41:00.000000000',\n",
       "       '2020-02-29T23:42:00.000000000', ...,\n",
       "       '2020-03-12T06:15:00.000000000', '2020-03-12T06:16:00.000000000',\n",
       "       '2020-03-12T06:17:00.000000000'], dtype='<U48')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_info['dataset_config']['val_timestamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the output\n",
    "\n",
    "timestamps = pd.to_datetime(run_info['dataset_config']['val_timestamps'])\n",
    "starttime, endtime = timestamps[0], timestamps[-1]\n",
    "\n",
    "# # handle time related variables\n",
    "# starttime = pd.to_datetime(timestamps[0, 0])\n",
    "# endtime = pd.to_datetime(timestamps[-1, -1]) + pd.Timedelta(minutes=steps_ahead)\n",
    "\n",
    "endogenous_vars = dataset_args['endogenous_vars']\n",
    "targets, _, _, _ = load_dataframe_from_HDF5(data_file_path, \"combined_data/clean\", columns=endogenous_vars, starttime=starttime, endtime=endtime, complete_range=True)\n",
    "targets = targets.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae(predictions, targets):\n",
    "    # Calculate the mean absolute error\n",
    "    assert predictions.shape == targets.shape, \"Predictions and targets must have the same shape\"\n",
    "    mae = np.sum(np.abs(predictions - targets)) / len(predictions)\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean predictor\n",
    "mean_predictions = np.mean(targets, axis=0)\n",
    "# create an a array of the same shape as the targets\n",
    "mean_predictions = np.tile(mean_predictions, (len(targets))).reshape(len(targets), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictor MAE: 0.014198638065767656\n"
     ]
    }
   ],
   "source": [
    "# evaluate the MAE\n",
    "mae = evaluate_mae(mean_predictions, targets)\n",
    "\n",
    "print(f\"Mean predictor MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous step predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next step based on the last value, targets is (9000) shape\n",
    "previous_values = targets[:-1] # remove the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous value predictor MAE: 0.0009065714109749338\n"
     ]
    }
   ],
   "source": [
    "mae = evaluate_mae(previous_values, targets[1:]) # remove the first value\n",
    "print(f\"Previous value predictor MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- very low learning rate???\n",
    "- visualize 1 event per month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# OLD:\n",
    "\n",
    "### Considerations:\n",
    "\n",
    "\n",
    "- **Prediction horizon**: \n",
    "    - *1-step-ahead*: focusing on anomaly detection, a 1-step-ahead prediction horizon is chosen for its simplicity.\n",
    "    - *considered*:\n",
    "      - *Multi-step-ahead*: predict multiple steps ahead and compare the predictions with the actual values to detect anomalies. This approach may be more accurate but also more complex.\n",
    "- **Model expandability**:\n",
    "    - *Input*: simply increase the number of input features to include data from multiple sensors.\n",
    "      - *considered*: \n",
    "          - Multiple Models: train a separate model for each sensor and combine their predictions for anomaly detection. But this approach may be less efficient,harder to manage and won't capture interactions between sensors.\n",
    "- **Rain data**:\n",
    "    - *In Output and Learned*: If rain data is a critical factor in detecting anomalies, include it in the output and allow the model to learn its patterns. This approach can help the model differentiate between anomalies caused by rain and other factors. Learn its pattern, then better to predict the anomalies.\n",
    "    - *considered*:\n",
    "        - Not in Output: If rain data is not directly related to the anomalies you're interested in, you might exclude it from the output.\n",
    "        - In Output but Masked in Loss: If rain data affects the system but should not be considered an anomaly, you can include it in the output but mask it in the loss function. This way, the model learns to predict rain data without penalizing deviations.\n",
    "\n",
    "- **Missing data**: mask it in the loss function? what values should it have as input?\n",
    "    - *0.1-1 Range and Masking in Loss*: Normalize the data to a range of 0.1-1 and impute missing values with 0. Then, mask the missing values in the loss function so that the model doesn't penalize them.\n",
    "    - *considered*:\n",
    "        - *Imputing*: keeping 0-1 range but impute with e.g. mean or -1\n",
    "        - *Indicator*: add an indicator feature that specifies whether the value is missing or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Tue Dec 17 17:21:57 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:37:00.0 Off |                    0 |
| N/A   33C    P0             43W /  250W |       1MiB /  40960MiB |      0%   E. Process |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Warning: ['training_args', 'lr'] is not a list; must be for hparam search
Warning: ['model_args', 'hidden_size'] is not a list; must be for hparam search
Warning: ['model_args', 'num_heads'] is not a list; must be for hparam search
Warning: ['model_args', 'num_layers'] is not a list; must be for hparam search

##################################################
EXPERIMENT 1/1
Save folder: /work3/s194262/GitHub/fault_management_uds/models/transformer/lr=0.0001_hidden_size=128_num_heads=8_num_layers=2_241217_1722

Hyperparameters: {'training_args/lr': 0.0001, 'model_args/hidden_size': 128, 'model_args/num_heads': 8, 'model_args/num_layers': 2}
##################################################

Validity: 94418 minutes are invalid.
Data validation passed.
Model does not have additional configurations.
Using CUDA
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.05it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/62089 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s] Epoch 0:   8%|â–Š         | 5000/62089 [01:34<17:58, 52.91it/s]Epoch 0:   8%|â–Š         | 5000/62089 [01:34<17:58, 52.91it/s, v_num=0, train_loss_step=6.49e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [03:07<16:15, 53.39it/s, v_num=0, train_loss_step=6.49e-5]Epoch 0:  16%|â–ˆâ–Œ        | 10000/62089 [03:07<16:15, 53.39it/s, v_num=0, train_loss_step=3.4e-6] Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:39<14:37, 53.68it/s, v_num=0, train_loss_step=3.4e-6]Epoch 0:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:39<14:37, 53.68it/s, v_num=0, train_loss_step=1.48e-5]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:11<13:01, 53.89it/s, v_num=0, train_loss_step=1.48e-5]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:11<13:01, 53.89it/s, v_num=0, train_loss_step=1.53e-5]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:43<11:26, 53.99it/s, v_num=0, train_loss_step=1.53e-5]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:43<11:26, 53.99it/s, v_num=0, train_loss_step=3.38e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:15<09:53, 54.05it/s, v_num=0, train_loss_step=3.38e-6]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:15<09:53, 54.05it/s, v_num=0, train_loss_step=1.08e-5]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:47<08:21, 54.02it/s, v_num=0, train_loss_step=1.08e-5]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:47<08:21, 54.02it/s, v_num=0, train_loss_step=2.57e-6]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:20<06:48, 54.04it/s, v_num=0, train_loss_step=2.57e-6]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:20<06:48, 54.04it/s, v_num=0, train_loss_step=2.33e-6]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:52<05:16, 54.05it/s, v_num=0, train_loss_step=2.33e-6]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:52<05:16, 54.05it/s, v_num=0, train_loss_step=5.03e-6]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:25<03:43, 54.05it/s, v_num=0, train_loss_step=5.03e-6]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:25<03:43, 54.05it/s, v_num=0, train_loss_step=1.54e-6]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:57<02:11, 54.05it/s, v_num=0, train_loss_step=1.54e-6]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:57<02:11, 54.05it/s, v_num=0, train_loss_step=1.25e-5]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:29<00:38, 54.07it/s, v_num=0, train_loss_step=1.25e-5]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:29<00:38, 54.07it/s, v_num=0, train_loss_step=3.57e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:08<00:00, 54.07it/s, v_num=0, train_loss_step=3.57e-6]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [19:08<00:00, 54.07it/s, v_num=0, train_loss_step=4.8e-6] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.60it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.75it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.65it/s][A
                                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [22:02<00:00, 46.94it/s, v_num=0, train_loss_step=4.8e-6, val_loss=1.09e-5]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [22:02<00:00, 46.94it/s, v_num=0, train_loss_step=4.8e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 0:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]            Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:32<17:38, 53.93it/s, v_num=0, train_loss_step=4.8e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:   8%|â–Š         | 5000/62089 [01:32<17:38, 53.93it/s, v_num=0, train_loss_step=6.2e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:58, 54.33it/s, v_num=0, train_loss_step=6.2e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:58, 54.33it/s, v_num=0, train_loss_step=8.71e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:24, 54.47it/s, v_num=0, train_loss_step=8.71e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:24, 54.47it/s, v_num=0, train_loss_step=3.41e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:51, 54.54it/s, v_num=0, train_loss_step=3.41e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:51, 54.54it/s, v_num=0, train_loss_step=3.4e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5] Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:19, 54.61it/s, v_num=0, train_loss_step=3.4e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:19, 54.61it/s, v_num=0, train_loss_step=1.53e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:47, 54.59it/s, v_num=0, train_loss_step=1.53e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:47, 54.59it/s, v_num=0, train_loss_step=2.17e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:39<08:14, 54.76it/s, v_num=0, train_loss_step=2.17e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:39<08:14, 54.76it/s, v_num=0, train_loss_step=6.29e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:08<06:42, 54.89it/s, v_num=0, train_loss_step=6.29e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:08<06:42, 54.89it/s, v_num=0, train_loss_step=3e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]   Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:40<05:11, 54.88it/s, v_num=0, train_loss_step=3e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:40<05:11, 54.88it/s, v_num=0, train_loss_step=4.25e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:11<03:40, 54.84it/s, v_num=0, train_loss_step=4.25e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:11<03:40, 54.84it/s, v_num=0, train_loss_step=1.82e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:43<02:09, 54.82it/s, v_num=0, train_loss_step=1.82e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:43<02:09, 54.82it/s, v_num=0, train_loss_step=6.03e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:14<00:38, 54.81it/s, v_num=0, train_loss_step=6.03e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:14<00:38, 54.81it/s, v_num=0, train_loss_step=2.75e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:51<00:00, 54.89it/s, v_num=0, train_loss_step=2.75e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:51<00:00, 54.89it/s, v_num=0, train_loss_step=2.79e-6, val_loss=1.09e-5, train_loss_epoch=9.39e-5]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.50it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.51it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.51it/s][A
                                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:45<00:00, 47.55it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.71e-6, train_loss_epoch=9.39e-5]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:45<00:00, 47.55it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 1:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]            Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:32<17:38, 53.93it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:   8%|â–Š         | 5000/62089 [01:32<17:38, 53.93it/s, v_num=0, train_loss_step=1.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:01, 54.18it/s, v_num=0, train_loss_step=1.79e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:01, 54.18it/s, v_num=0, train_loss_step=4.57e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.42it/s, v_num=0, train_loss_step=4.57e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.42it/s, v_num=0, train_loss_step=5.87e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:51, 54.53it/s, v_num=0, train_loss_step=5.87e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:51, 54.53it/s, v_num=0, train_loss_step=5.46e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:20, 54.50it/s, v_num=0, train_loss_step=5.46e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:20, 54.50it/s, v_num=0, train_loss_step=3.89e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:48, 54.55it/s, v_num=0, train_loss_step=3.89e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:48, 54.55it/s, v_num=0, train_loss_step=3.67e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.62it/s, v_num=0, train_loss_step=3.67e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.62it/s, v_num=0, train_loss_step=3.07e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.59it/s, v_num=0, train_loss_step=3.07e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.59it/s, v_num=0, train_loss_step=1.14e-5, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.57it/s, v_num=0, train_loss_step=1.14e-5, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.57it/s, v_num=0, train_loss_step=3.41e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.56it/s, v_num=0, train_loss_step=3.41e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.56it/s, v_num=0, train_loss_step=2.44e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:48<02:10, 54.51it/s, v_num=0, train_loss_step=2.44e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:48<02:10, 54.51it/s, v_num=0, train_loss_step=3.54e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:20<00:38, 54.53it/s, v_num=0, train_loss_step=3.54e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:20<00:38, 54.53it/s, v_num=0, train_loss_step=3.25e-5, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:58<00:00, 54.52it/s, v_num=0, train_loss_step=3.25e-5, val_loss=6.71e-6, train_loss_epoch=7.24e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:58<00:00, 54.52it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.71e-6, train_loss_epoch=7.24e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:05<01:47, 75.94it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:11<00:42, 75.77it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.66it/s][A
                                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:53<00:00, 47.28it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.13e-6, train_loss_epoch=7.24e-6]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:53<00:00, 47.28it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 2:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]            Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:32<17:40, 53.81it/s, v_num=0, train_loss_step=1.73e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:   8%|â–Š         | 5000/62089 [01:32<17:40, 53.81it/s, v_num=0, train_loss_step=1.36e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:01, 54.16it/s, v_num=0, train_loss_step=1.36e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:01, 54.16it/s, v_num=0, train_loss_step=3.19e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.38it/s, v_num=0, train_loss_step=3.19e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.38it/s, v_num=0, train_loss_step=3.68e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:07<12:53, 54.42it/s, v_num=0, train_loss_step=3.68e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:07<12:53, 54.42it/s, v_num=0, train_loss_step=1.97e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:20, 54.48it/s, v_num=0, train_loss_step=1.97e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:20, 54.48it/s, v_num=0, train_loss_step=2.14e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:10<09:48, 54.52it/s, v_num=0, train_loss_step=2.14e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:10<09:48, 54.52it/s, v_num=0, train_loss_step=2.16e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:42<08:17, 54.48it/s, v_num=0, train_loss_step=2.16e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:42<08:17, 54.48it/s, v_num=0, train_loss_step=5.72e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:13<06:44, 54.57it/s, v_num=0, train_loss_step=5.72e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:13<06:44, 54.57it/s, v_num=0, train_loss_step=3.06e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.57it/s, v_num=0, train_loss_step=3.06e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.57it/s, v_num=0, train_loss_step=1.95e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.54it/s, v_num=0, train_loss_step=1.95e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.54it/s, v_num=0, train_loss_step=6.94e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:47<02:09, 54.57it/s, v_num=0, train_loss_step=6.94e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:47<02:09, 54.57it/s, v_num=0, train_loss_step=2.89e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:18<00:38, 54.60it/s, v_num=0, train_loss_step=2.89e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:18<00:38, 54.60it/s, v_num=0, train_loss_step=1.82e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:57<00:00, 54.60it/s, v_num=0, train_loss_step=1.82e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:57<00:00, 54.60it/s, v_num=0, train_loss_step=4.95e-6, val_loss=6.13e-6, train_loss_epoch=6.49e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.24it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.50it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.52it/s][A
                                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:51<00:00, 47.33it/s, v_num=0, train_loss_step=4.95e-6, val_loss=4.59e-6, train_loss_epoch=6.49e-6]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:51<00:00, 47.33it/s, v_num=0, train_loss_step=4.95e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 3:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]            Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:32<17:34, 54.15it/s, v_num=0, train_loss_step=4.95e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:   8%|â–Š         | 5000/62089 [01:32<17:34, 54.15it/s, v_num=0, train_loss_step=3.65e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [03:03<15:56, 54.44it/s, v_num=0, train_loss_step=3.65e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  16%|â–ˆâ–Œ        | 10000/62089 [03:03<15:56, 54.44it/s, v_num=0, train_loss_step=3.91e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:34<14:22, 54.58it/s, v_num=0, train_loss_step=3.91e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:34<14:22, 54.58it/s, v_num=0, train_loss_step=2.66e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:05<12:50, 54.65it/s, v_num=0, train_loss_step=2.66e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:05<12:50, 54.65it/s, v_num=0, train_loss_step=2.07e-5, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:18, 54.63it/s, v_num=0, train_loss_step=2.07e-5, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:18, 54.63it/s, v_num=0, train_loss_step=2.71e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:46, 54.67it/s, v_num=0, train_loss_step=2.71e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:46, 54.67it/s, v_num=0, train_loss_step=2.47e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:39<08:15, 54.69it/s, v_num=0, train_loss_step=2.47e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:39<08:15, 54.69it/s, v_num=0, train_loss_step=3.3e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6] Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:11<06:43, 54.68it/s, v_num=0, train_loss_step=3.3e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:11<06:43, 54.68it/s, v_num=0, train_loss_step=5.27e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:42<05:12, 54.70it/s, v_num=0, train_loss_step=5.27e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:42<05:12, 54.70it/s, v_num=0, train_loss_step=3.1e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6] Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:13<03:40, 54.72it/s, v_num=0, train_loss_step=3.1e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:13<03:40, 54.72it/s, v_num=0, train_loss_step=4.13e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:45<02:09, 54.71it/s, v_num=0, train_loss_step=4.13e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:45<02:09, 54.71it/s, v_num=0, train_loss_step=5.54e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:15<00:38, 54.75it/s, v_num=0, train_loss_step=5.54e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:15<00:38, 54.75it/s, v_num=0, train_loss_step=6.9e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6] Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:54<00:00, 54.75it/s, v_num=0, train_loss_step=6.9e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:54<00:00, 54.75it/s, v_num=0, train_loss_step=1.63e-6, val_loss=4.59e-6, train_loss_epoch=6.28e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.37it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.31it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:55<00:00, 75.42it/s][A
                                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:49<00:00, 47.43it/s, v_num=0, train_loss_step=1.63e-6, val_loss=6.72e-6, train_loss_epoch=6.28e-6]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:49<00:00, 47.43it/s, v_num=0, train_loss_step=1.63e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 4:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]            Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:32<17:35, 54.10it/s, v_num=0, train_loss_step=1.63e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:   8%|â–Š         | 5000/62089 [01:32<17:35, 54.10it/s, v_num=0, train_loss_step=2.08e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [03:03<15:55, 54.53it/s, v_num=0, train_loss_step=2.08e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  16%|â–ˆâ–Œ        | 10000/62089 [03:03<15:55, 54.53it/s, v_num=0, train_loss_step=2.95e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:34<14:22, 54.63it/s, v_num=0, train_loss_step=2.95e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:34<14:22, 54.63it/s, v_num=0, train_loss_step=3.67e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:05<12:49, 54.67it/s, v_num=0, train_loss_step=3.67e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:05<12:49, 54.67it/s, v_num=0, train_loss_step=1.27e-5, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:36<11:17, 54.72it/s, v_num=0, train_loss_step=1.27e-5, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:36<11:17, 54.72it/s, v_num=0, train_loss_step=6.59e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:47, 54.66it/s, v_num=0, train_loss_step=6.59e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:47, 54.66it/s, v_num=0, train_loss_step=3.37e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.69it/s, v_num=0, train_loss_step=3.37e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.69it/s, v_num=0, train_loss_step=2.53e-5, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:11<06:43, 54.70it/s, v_num=0, train_loss_step=2.53e-5, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:11<06:43, 54.70it/s, v_num=0, train_loss_step=1.93e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:43<05:12, 54.65it/s, v_num=0, train_loss_step=1.93e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:43<05:12, 54.65it/s, v_num=0, train_loss_step=2.21e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:14<03:41, 54.67it/s, v_num=0, train_loss_step=2.21e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:14<03:41, 54.67it/s, v_num=0, train_loss_step=4.38e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:44<02:09, 54.74it/s, v_num=0, train_loss_step=4.38e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:44<02:09, 54.74it/s, v_num=0, train_loss_step=3.45e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:16<00:38, 54.71it/s, v_num=0, train_loss_step=3.45e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:16<00:38, 54.71it/s, v_num=0, train_loss_step=2.44e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:54<00:00, 54.72it/s, v_num=0, train_loss_step=2.44e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:54<00:00, 54.72it/s, v_num=0, train_loss_step=2.93e-6, val_loss=6.72e-6, train_loss_epoch=6.08e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:05<01:47, 76.44it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:11<00:41, 76.20it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:53<00:00, 75.97it/s][A
                                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:48<00:00, 47.45it/s, v_num=0, train_loss_step=2.93e-6, val_loss=9.36e-6, train_loss_epoch=6.08e-6]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:48<00:00, 47.45it/s, v_num=0, train_loss_step=2.93e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]   Epoch 5:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]            Epoch 6:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:32<17:36, 54.03it/s, v_num=0, train_loss_step=2.93e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:   8%|â–Š         | 5000/62089 [01:32<17:36, 54.03it/s, v_num=0, train_loss_step=4.27e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:58, 54.34it/s, v_num=0, train_loss_step=4.27e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:58, 54.34it/s, v_num=0, train_loss_step=2.74e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.42it/s, v_num=0, train_loss_step=2.74e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:25, 54.42it/s, v_num=0, train_loss_step=1.21e-5, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:07<12:53, 54.45it/s, v_num=0, train_loss_step=1.21e-5, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:07<12:53, 54.45it/s, v_num=0, train_loss_step=4.17e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:19, 54.57it/s, v_num=0, train_loss_step=4.17e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:38<11:19, 54.57it/s, v_num=0, train_loss_step=2.7e-6, val_loss=9.36e-6, train_loss_epoch=6e-6] Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:47, 54.58it/s, v_num=0, train_loss_step=2.7e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:09<09:47, 54.58it/s, v_num=0, train_loss_step=1.92e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:41<08:16, 54.57it/s, v_num=0, train_loss_step=1.92e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:41<08:16, 54.57it/s, v_num=0, train_loss_step=3.33e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.59it/s, v_num=0, train_loss_step=3.33e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.59it/s, v_num=0, train_loss_step=2.38e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.60it/s, v_num=0, train_loss_step=2.38e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:44<05:13, 54.60it/s, v_num=0, train_loss_step=2.44e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.54it/s, v_num=0, train_loss_step=2.44e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:16<03:41, 54.54it/s, v_num=0, train_loss_step=2.81e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:48<02:09, 54.56it/s, v_num=0, train_loss_step=2.81e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:48<02:09, 54.56it/s, v_num=0, train_loss_step=3.46e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:19<00:38, 54.57it/s, v_num=0, train_loss_step=3.46e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:19<00:38, 54.57it/s, v_num=0, train_loss_step=1.91e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:58<00:00, 54.53it/s, v_num=0, train_loss_step=1.91e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:58<00:00, 54.53it/s, v_num=0, train_loss_step=5.41e-6, val_loss=9.36e-6, train_loss_epoch=6e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.52it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.65it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.64it/s][A
                                                                              [AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:53<00:00, 47.28it/s, v_num=0, train_loss_step=5.41e-6, val_loss=6.98e-6, train_loss_epoch=6e-6]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:53<00:00, 47.28it/s, v_num=0, train_loss_step=5.41e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 6:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=5.41e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]            Epoch 7:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=5.41e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:   8%|â–Š         | 5000/62089 [01:32<17:39, 53.87it/s, v_num=0, train_loss_step=5.41e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:   8%|â–Š         | 5000/62089 [01:32<17:39, 53.87it/s, v_num=0, train_loss_step=4.61e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:00, 54.23it/s, v_num=0, train_loss_step=4.61e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<16:00, 54.23it/s, v_num=0, train_loss_step=2.45e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:36<14:27, 54.31it/s, v_num=0, train_loss_step=2.45e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:36<14:27, 54.31it/s, v_num=0, train_loss_step=1.63e-5, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:08<12:54, 54.33it/s, v_num=0, train_loss_step=1.63e-5, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:08<12:54, 54.33it/s, v_num=0, train_loss_step=3.97e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:39<11:21, 54.43it/s, v_num=0, train_loss_step=3.97e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:39<11:21, 54.43it/s, v_num=0, train_loss_step=6.33e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:10<09:48, 54.53it/s, v_num=0, train_loss_step=6.33e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:10<09:48, 54.53it/s, v_num=0, train_loss_step=3.29e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:41<08:16, 54.56it/s, v_num=0, train_loss_step=3.29e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:41<08:16, 54.56it/s, v_num=0, train_loss_step=5.28e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.60it/s, v_num=0, train_loss_step=5.28e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.60it/s, v_num=0, train_loss_step=3.28e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:43<05:12, 54.63it/s, v_num=0, train_loss_step=3.28e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:43<05:12, 54.63it/s, v_num=0, train_loss_step=2.25e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:15<03:41, 54.59it/s, v_num=0, train_loss_step=2.25e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:15<03:41, 54.59it/s, v_num=0, train_loss_step=2.62e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:47<02:09, 54.61it/s, v_num=0, train_loss_step=2.62e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:47<02:09, 54.61it/s, v_num=0, train_loss_step=4.1e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6] Epoch 7:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:17<00:38, 54.65it/s, v_num=0, train_loss_step=4.1e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:17<00:38, 54.65it/s, v_num=0, train_loss_step=5.88e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:55<00:00, 54.67it/s, v_num=0, train_loss_step=5.88e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6]Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:55<00:00, 54.67it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.98e-6, train_loss_epoch=5.71e-6] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.61it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.73it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:53<00:00, 75.90it/s][A
                                                                              [AEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:49<00:00, 47.41it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.19e-6, train_loss_epoch=5.71e-6]Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:49<00:00, 47.41it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 7:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]            Epoch 8:   0%|          | 0/62089 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:   8%|â–Š         | 5000/62089 [01:32<17:35, 54.09it/s, v_num=0, train_loss_step=2.7e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:   8%|â–Š         | 5000/62089 [01:32<17:35, 54.09it/s, v_num=0, train_loss_step=1.39e-5, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:59, 54.28it/s, v_num=0, train_loss_step=1.39e-5, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  16%|â–ˆâ–Œ        | 10000/62089 [03:04<15:59, 54.28it/s, v_num=0, train_loss_step=3.63e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:24, 54.45it/s, v_num=0, train_loss_step=3.63e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  24%|â–ˆâ–ˆâ–       | 15000/62089 [04:35<14:24, 54.45it/s, v_num=0, train_loss_step=2.85e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:50, 54.61it/s, v_num=0, train_loss_step=2.85e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  32%|â–ˆâ–ˆâ–ˆâ–      | 20000/62089 [06:06<12:50, 54.61it/s, v_num=0, train_loss_step=2.07e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:19, 54.60it/s, v_num=0, train_loss_step=2.07e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 25000/62089 [07:37<11:19, 54.60it/s, v_num=0, train_loss_step=2.19e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:46, 54.68it/s, v_num=0, train_loss_step=2.19e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30000/62089 [09:08<09:46, 54.68it/s, v_num=0, train_loss_step=5.31e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.65it/s, v_num=0, train_loss_step=5.31e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 35000/62089 [10:40<08:15, 54.65it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.64it/s, v_num=0, train_loss_step=2.79e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40000/62089 [12:12<06:44, 54.64it/s, v_num=0, train_loss_step=2.49e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:42<05:12, 54.68it/s, v_num=0, train_loss_step=2.49e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45000/62089 [13:42<05:12, 54.68it/s, v_num=0, train_loss_step=3.8e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6] Epoch 8:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:14<03:41, 54.66it/s, v_num=0, train_loss_step=3.8e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 50000/62089 [15:14<03:41, 54.66it/s, v_num=0, train_loss_step=3.48e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:46<02:09, 54.66it/s, v_num=0, train_loss_step=3.48e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55000/62089 [16:46<02:09, 54.66it/s, v_num=0, train_loss_step=2.1e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6] Epoch 8:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:17<00:38, 54.65it/s, v_num=0, train_loss_step=2.1e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 60000/62089 [18:17<00:38, 54.65it/s, v_num=0, train_loss_step=4.69e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:56<00:00, 54.64it/s, v_num=0, train_loss_step=4.69e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [18:56<00:00, 54.64it/s, v_num=0, train_loss_step=1.39e-6, val_loss=6.19e-6, train_loss_epoch=5.85e-6]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13200 [00:00<?, ?it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5000/13200 [01:06<01:48, 75.60it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 10000/13200 [02:12<00:42, 75.60it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13200/13200 [02:54<00:00, 75.55it/s][A
                                                                              [AEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:51<00:00, 47.36it/s, v_num=0, train_loss_step=1.39e-6, val_loss=4.65e-6, train_loss_epoch=5.85e-6]Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:51<00:00, 47.36it/s, v_num=0, train_loss_step=1.39e-6, val_loss=4.65e-6, train_loss_epoch=5.87e-6]Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62089/62089 [21:51<00:00, 47.35it/s, v_num=0, train_loss_step=1.39e-6, val_loss=4.65e-6, train_loss_epoch=5.87e-6]
Using CUDA
Model loaded from /work3/s194262/GitHub/fault_management_uds/models/transformer/lr=0.0001_hidden_size=128_num_heads=8_num_layers=2_241217_1722/1_split/epoch=03-val_loss=0.0000046.ckpt
Loggers: dict_keys(['train_loss_step', 'epoch', 'val_loss', 'train_loss_epoch'])

Run lr=0.0001_hidden_size=128_num_heads=8_num_layers=2_241217_1722 completed



------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23452677: <_transf_complex> in cluster <dcc> Done

Job <_transf_complex> was submitted from host <hpclogin1> by user <s194262> in cluster <dcc> at Tue Dec 17 15:38:15 2024
Job was executed on host(s) <4*n-62-12-24>, in queue <gpua100>, as user <s194262> in cluster <dcc> at Tue Dec 17 17:21:54 2024
</zhome/96/8/147177> was used as the home directory.
</work3/s194262/GitHub/fault_management_uds> was used as the working directory.
Started at Tue Dec 17 17:21:54 2024
Terminated at Tue Dec 17 20:51:20 2024
Results reported at Tue Dec 17 20:51:20 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh 

### -- set the job Name --
#BSUB -J _transf_complex
### -- specify files --
#BSUB -o /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J_transf_complex_.out
#BSUB -e /work3/s194262/GitHub/fault_management_uds/hpc_logs/%J_transf_complex.err

### General options
### â€“- specify queue --
#BSUB -q gpua100
### -- ask for number of cores (default: 1) --
#BSUB -n 4
### -- Select the resources: 1 gpu in exclusive process mode --
#BSUB -gpu "num=1:mode=exclusive_process"
### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now
#BSUB -W 24:00
### -- request _ GB of system-memory --
#BSUB -R "rusage[mem=4GB]"
#BSUB -R "span[hosts=1]"


nvidia-smi
module load cuda/11.8

source /work3/s194262/thesis/bin/activate

cd /work3/s194262/GitHub/fault_management_uds

python fault_management_uds/main.py --config "transformer/complex_lr.yaml" --num_workers 0



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12004.00 sec.
    Max Memory :                                 3330 MB
    Average Memory :                             2751.01 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13054.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                12
    Run time :                                   12565 sec.
    Turnaround time :                            18785 sec.

The output (if any) is above this job summary.



PS:

Read file </work3/s194262/GitHub/fault_management_uds/hpc_logs/23452677_transf_complex.err> for stderr output of this job.

